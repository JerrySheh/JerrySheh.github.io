import{_ as a,c as s,f as t,o as n}from"./app-D22ydJtp.js";const i="/images/hadoop/secondaryNameNode.png",d="/images/hadoop/node.png",o="/images/hadoop/YARN.png",l={};function p(r,e){return n(),s("div",null,e[0]||(e[0]=[t(`<h1 id="前言" tabindex="-1"><a class="header-anchor" href="#前言"><span>前言</span></a></h1><p>当数据量变大的时候，一台机器完成一个问题要计算好久好久。这时候就需要多台机器并行运算。然而，每台机器不能用单台机器运行的算法，自己算自己的。而是要有不同的分工，联合起来共同算完这个问题。</p><p>Hadoop就是这样的一个大数据处理框架。其中包括很多开源的处理框架，比如：</p><ul><li><strong>文件存储</strong>：Hadoop HDFS、Tachyon、KFS</li><li><strong>离线计算</strong>：Hadoop MapReduce、Spark</li><li><strong>流式、实时计算</strong>：Storm、Spark Streaming、S4、Heron</li><li><strong>K-V、NOSQL数据库</strong>：HBase、Redis、MongoDB</li><li><strong>资源管理</strong>：YARN、Mesos</li><li><strong>日志收集</strong>：Flume、Scribe、Logstash、Kibana</li><li><strong>消息系统</strong>：Kafka、StormMQ、ZeroMQ、RabbitMQ</li><li><strong>查询分析</strong>：Hive、Impala、Pig、Presto、Phoenix、SparkSQL、Drill、Flink、Kylin、Druid</li><li><strong>分布式协调服务</strong>：Zookeeper</li><li><strong>集群管理与监控</strong>：Ambari、Ganglia、Nagios、Cloudera Manager</li><li><strong>数据挖掘、机器学习</strong>：Mahout、Spark MLLib</li><li><strong>数据同步</strong>：Sqoop</li><li><strong>任务调度</strong>：Oozie</li></ul><p>那这么多，要怎么学呢？吴军博士在《数学之美》中提到：</p><blockquote><p>分治算法是计算机科学中最漂亮的工具之一，我称为“各个击破”法。</p></blockquote><p>我们就来各个击破。当然，先挑重点的学习。</p><hr><h1 id="mapreduce" tabindex="-1"><a class="header-anchor" href="#mapreduce"><span>MapReduce</span></a></h1><p>假设我们要统计一本10000页的书里面，&quot;apple&quot;、&quot;banana&quot;、&quot;orange&quot;这三个单词出现的次数。由于规模很大，用一台机器来算，要算很久。我们能不能把规模缩小，交给多台机器去算呢？我们容易想到，可以拿4台服务器，假设为1，2，3，4，每台服务器计算2500页，各自算各自的。</p><p>好了，现在每台服务器把各自负责的2500页统计完了。但我们关心的是 10000 页这个总量里面单词出现的次数，而不是4个独立的2500页。这 4 个 2500 页的结果分别保存在1，2，3，4四台服务器上。我们现在要想办法合并结果。</p><p>于是我们找来另外三台服务器，假设为A，B，C：</p><ul><li>让 A 计算在机器1，2，3，4上面 &quot;apple&quot; 单词出现的总次数。</li><li>让 B 计算在机器1，2，3，4上面 &quot;banana&quot; 单词出现的总次数。</li><li>让 C 计算在机器1，2，3，4上面 &quot;orange&quot; 单词出现的总次数。</li></ul><p>这样，我们就知道每个单词出现的总次数了。</p><p>以上就是 Hadoop 简单的基本原理。我们称为 MapReduce模型。这个模型分为三个阶段：</p><ul><li><strong>Map阶段</strong>：每台机器先处理本机上的数据。（对于机器1来说，就是计算前2500页&quot;apple&quot;出现的次数）</li><li><strong>Shuffle阶段</strong>：各个机器处理完自己的数据后，用另一批机器（或者还是这些机器）去收集某个数据的总和。（对于机器 A 来说，就是把 4 个 2500页 的&quot;apple&quot; 汇总。）</li><li><strong>Reduce阶段</strong>：把多个数据的总和规约、合并，出最终结果。（把汇总的“apple”、&quot;banana&quot;、&quot;orange&quot; 归并）</li></ul><h2 id="mapreduce编程模型" tabindex="-1"><a class="header-anchor" href="#mapreduce编程模型"><span>MapReduce编程模型</span></a></h2><p>首先，程序会先读取文件，交给 InputFormat 预处理。InputFormat主要做两件事：</p><ol><li><strong>getSplits</strong>：返回 InputSplit 数组，即对数据进行 split 分片，每片交给map操作一次</li><li><strong>getRecordReader</strong>：返回 RecordReader 对象，对每个 split 分片进行转换为 key-value 键值对格式传递给map</li></ol><p>实际上常用的是 TextInputFormat，就是将文件的内容按行分割（split），形成 K-V 对。key是偏移量，value是该行的值。使用的是hadoop内置的数据类型，比如longwritable、text等。</p><p>例如，原始文件为</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>hello hadoop</span></span>
<span class="line"><span>and hello spark</span></span>
<span class="line"><span>spark</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>TextInputFormat预处理后的结果为</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>&lt;0，hello hadoop&gt;</span></span>
<span class="line"><span>&lt;13, hello spark&gt;</span></span>
<span class="line"><span>&lt;29, spark&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>之后，将这个 K-V 对集合输入 mapper，进行业务处理过程，将其转换成需要的key-value再输出。</p><p>mapper后的结果为</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>&lt;hello, 1&gt;</span></span>
<span class="line"><span>&lt;hadoop, 1&gt;</span></span>
<span class="line"><span>&lt;hello, 1&gt;</span></span>
<span class="line"><span>&lt;spark, 1&gt;</span></span>
<span class="line"><span>&lt;spark, 1&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>之后，进行 shuffle(洗牌)操作，这个过程把 key 相同的value合并成list，作为reduce输入。</p><p>shuffle后的结果为</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>&lt;hello, &lt;1,1&gt;&gt;</span></span>
<span class="line"><span>&lt;hadoop, 1&gt;</span></span>
<span class="line"><span>&lt;spark, &lt;1,1&gt;&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>reduce的结果为</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>&lt;hello, 2&gt;</span></span>
<span class="line"><span>&lt;hadoop, 1&gt;</span></span>
<span class="line"><span>&lt;spark, 2&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr><h1 id="hadoop-distribute-filesystem-hdfs" tabindex="-1"><a class="header-anchor" href="#hadoop-distribute-filesystem-hdfs"><span>Hadoop Distribute Filesystem (HDFS)</span></a></h1><p>当数据集大小超过一台计算机的存储能力时，就有必要对它进行分区（partition）并存储到多台计算机上。管理网络中跨多台计算机存储的文件系统称为 <strong>分布式文件系统（distribute filesystem）</strong>。</p><p>Hadoop 自带一个分布式文件系统，称为 HDFS。</p><h2 id="hdfs-的设计" tabindex="-1"><a class="header-anchor" href="#hdfs-的设计"><span>HDFS 的设计</span></a></h2><p>包括可存储超大文件、流式数据访问、用于商用硬件（指的是普通硬件而不是精密昂贵的硬件）、低时间延迟的数据访问、大量的小文件、单用户写入和只添加等设计特点。</p><h3 id="数据块" tabindex="-1"><a class="header-anchor" href="#数据块"><span>数据块</span></a></h3><p>HDFS上的文件被划分为多个分块（chunk），作为独立的存储单元。</p><h3 id="namenode" tabindex="-1"><a class="header-anchor" href="#namenode"><span>NameNode</span></a></h3><p>HDFS 之所以可以存很大的文件，是因为每个文件都会被分成一些 data block，存在不同机器上。但是当我们操作 HDFS 时，并不需要关心数据是如何分布式存储在各个结点上的，HDFS 展现给我们的只是类似于普通 Linux 那样的文件系统。那么，数据怎么存，存在哪里，这些信息是谁管理的呢？这就需要 NameNode 了。</p><p>NameNode 主要是用来保存 HDFS 的元数据信息，比如命名空间信息，块信息等。当它运行的时候，这些信息存在内存中（也可以持久化到磁盘上）。<strong>namenode 负责记录一个文件有哪些 data block，以及这些 data block 分别存放在哪些机器上</strong>。</p><h3 id="secondarynamenode" tabindex="-1"><a class="header-anchor" href="#secondarynamenode"><span>SecondaryNameNode</span></a></h3><p>在 HDFS 中，有这么两个文件</p><ol><li><strong>fsimage</strong>：它是在 NameNode 启动时对整个文件系统的快照</li><li><strong>edit logs</strong>：它是在 NameNode 启动后，对文件系统的改动序列</li></ol><p>只有在 NameNode 重启时，edit logs才会被合并到 fsimage 中，从而得到一个文件系统的最新快照。但是，在产品集群中，NameNode 是很少重启的，因此 edit logs 可能会变得非常大，导致下一次 NameNode 启动时要合并很多文件，启动时间非常久。</p><p>我们要做的事情是：如何在不重启 NameNode 的前提下，及时更新系统快照，减少edit logs文件的大小，得到一个最新的fsimage文件 ? SecondaryNameNode 就是负责做这件事的。其主要任务是 <strong>合并 NameNode 的edit logs（修改过的日志）到 fsimage（系统快照） 文件中</strong>。</p><p><img src="`+i+'" alt="secondaryNameNode"></p><h3 id="datanode" tabindex="-1"><a class="header-anchor" href="#datanode"><span>datanode</span></a></h3><p>datanode是工作节点，<strong>用于存储并检索数据块（data block）</strong>。定期向 namenode 发心跳包。</p><p><img src="'+d+'" alt=""></p><h3 id="当我们读取一个文件时发生了什么" tabindex="-1"><a class="header-anchor" href="#当我们读取一个文件时发生了什么"><span>当我们读取一个文件时发生了什么</span></a></h3><ol><li>HDFS client 联系 Name nodes，获取文件的 data blocks 组成、以及每个 data block 所在的机器以及具体存放位置；</li><li>HDFS client 联系 Data nodes, 进行具体的读写操作；</li></ol><h3 id="数据备份" tabindex="-1"><a class="header-anchor" href="#数据备份"><span>数据备份</span></a></h3><p>分布式文件系统中，文件存储在多台机器上。如果其中某一台故障了，系统要确保依然能够正常运行。HDFS 是如何保证在机器故障情况下文件数据依然不丢失的呢？说白了，就是做数据备份，也就是多存几份。我们可以手动配置备份数量，HDFS默认是 3 份。</p><p>一般存储 HDFS 文件的机器都是在机架（Rack）上的，很多数据中心里的故障都是一整个 Rack 出问题。因此通常在同一个 Rack 上储存一份，然后在另一个 Rack 上储存另两份。这样就保证数据有更高的安全性。</p><p>HDFS client 写文件创建新的 block 时，NameNode 会为这个 block 创建一个唯一 ID， 并决定由哪些 dataNode 来存放。被选中的 dataNode 组成一个队列，client 只向队列第一个 dataNode 写，第一个 dataNode 存储完毕后，继续向队列第二个 dataNode 传递。</p><h2 id="hdfs-的基本操作" tabindex="-1"><a class="header-anchor" href="#hdfs-的基本操作"><span>HDFS 的基本操作</span></a></h2><p>必须先启用 HDFS 之后才能进行操作。</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>./sbin/start-hdfs.sh</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>将本地文件上传到 hdfs 上（原路径只能是一个文件）</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>hdfs dfs -copyFromLocal /local/data /hdfs/data</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>和 copyFromLocal 区别是，put 原路径可以是文件夹等</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>hdfs dfs -put /tmp/ /hdfs/</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>查看根目录文件</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>hadoop fs -ls /</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>查看/tmp/data目录</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>hadoop fs -ls /tmp/data</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>查看 a.txt，与 -text 一样</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>hadoop fs -cat /tmp/a.txt</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>创建目录dir</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>hadoop fs -mkdir dir</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>删除目录dir</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>hadoop fs -rm -r dir</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><blockquote><p>在 HDFS 中，就不要 cd 了， 用 ls + 目录</p></blockquote><h3 id="hadoop-fs-和-hdfs-dfs的区别" tabindex="-1"><a class="header-anchor" href="#hadoop-fs-和-hdfs-dfs的区别"><span>Hadoop fs 和 hdfs dfs的区别</span></a></h3><p>Hadoop fs：使用面最广，可以操作任何文件系统。</p><p>hadoop dfs与hdfs dfs：只能操作HDFS文件系统相关（包括与Local FS间的操作），前者已经Deprecated，一般使用后者。</p><hr><h1 id="yet-another-resource-negotiator-yarn" tabindex="-1"><a class="header-anchor" href="#yet-another-resource-negotiator-yarn"><span>Yet Another Resource Negotiator (YARN)</span></a></h1><p>YARN 是 Hadoop 的集群资源管理系统。 YARN 提供请求和使用集群资源的API。但很少用于用户代码，因为在 YARN 之上的如MapReduce、Spark等分布式计算框架向用户隐藏了资源管理的细节。</p><p>一般来说，HDFS在Storage底层、YARN在Compute中间层，往上的Application上层才是MapReduce、Spark等计算框架。（甚至Application之上还能再封装一层，如Pig、Hive等）</p><p><img src="'+o+'" alt=""></p><p>Hadoop有两类长期运行的守护进程：</p><ul><li><strong>资源管理器</strong>：管理集群上资源的使用</li><li><strong>节点管理器</strong>：运行在集群中所有节点上切能够启动和监控容器的东西</li></ul><p>YARN 则是管理这两个守护进程的。</p><hr><h1 id="hive" tabindex="-1"><a class="header-anchor" href="#hive"><span>Hive</span></a></h1><p>hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。</p><hr><h1 id="小结" tabindex="-1"><a class="header-anchor" href="#小结"><span>小结</span></a></h1><p>HDFS是Hadoop提供的分布式存储框架，它可以用来存储海量数据，MapReduce是Hadoop提供的分布式计算框架，它可以用来统计和分析HDFS上的海量数据，而Hive则是SQL On Hadoop，Hive提供了SQL接口，开发人员只需要编写简单易上手的SQL语句，Hive负责把SQL翻译成MapReduce，提交运行。</p>',93)]))}const h=a(l,[["render",p],["__file","index.html.vue"]]),u=JSON.parse('{"path":"/article/vib0gdr6/","title":"Hadoop大数据生态（一）初识","lang":"zh-CN","frontmatter":{"title":"Hadoop大数据生态（一）初识","categories":["大数据","hadoop"],"tags":["Hadoop"],"abbrlink":"e2142b57","createTime":"2018/03/14 18:47:46","permalink":"/article/vib0gdr6/","description":"前言 当数据量变大的时候，一台机器完成一个问题要计算好久好久。这时候就需要多台机器并行运算。然而，每台机器不能用单台机器运行的算法，自己算自己的。而是要有不同的分工，联合起来共同算完这个问题。 Hadoop就是这样的一个大数据处理框架。其中包括很多开源的处理框架，比如： 文件存储：Hadoop HDFS、Tachyon、KFS 离线计算：Hadoop ...","head":[["meta",{"property":"og:url","content":"https://jerrysheh.com/article/vib0gdr6/"}],["meta",{"property":"og:site_name","content":"Jerry"}],["meta",{"property":"og:title","content":"Hadoop大数据生态（一）初识"}],["meta",{"property":"og:description","content":"前言 当数据量变大的时候，一台机器完成一个问题要计算好久好久。这时候就需要多台机器并行运算。然而，每台机器不能用单台机器运行的算法，自己算自己的。而是要有不同的分工，联合起来共同算完这个问题。 Hadoop就是这样的一个大数据处理框架。其中包括很多开源的处理框架，比如： 文件存储：Hadoop HDFS、Tachyon、KFS 离线计算：Hadoop ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://jerrysheh.com/images/hadoop/secondaryNameNode.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-10-20T05:02:32.000Z"}],["meta",{"property":"article:tag","content":"Hadoop"}],["meta",{"property":"article:modified_time","content":"2024-10-20T05:02:32.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Hadoop大数据生态（一）初识\\",\\"image\\":[\\"https://jerrysheh.com/images/hadoop/secondaryNameNode.png\\",\\"https://jerrysheh.com/images/hadoop/node.png\\",\\"https://jerrysheh.com/images/hadoop/YARN.png\\"],\\"dateModified\\":\\"2024-10-20T05:02:32.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"MapReduce编程模型","slug":"mapreduce编程模型","link":"#mapreduce编程模型","children":[]},{"level":2,"title":"HDFS 的设计","slug":"hdfs-的设计","link":"#hdfs-的设计","children":[{"level":3,"title":"数据块","slug":"数据块","link":"#数据块","children":[]},{"level":3,"title":"NameNode","slug":"namenode","link":"#namenode","children":[]},{"level":3,"title":"SecondaryNameNode","slug":"secondarynamenode","link":"#secondarynamenode","children":[]},{"level":3,"title":"datanode","slug":"datanode","link":"#datanode","children":[]},{"level":3,"title":"当我们读取一个文件时发生了什么","slug":"当我们读取一个文件时发生了什么","link":"#当我们读取一个文件时发生了什么","children":[]},{"level":3,"title":"数据备份","slug":"数据备份","link":"#数据备份","children":[]}]},{"level":2,"title":"HDFS 的基本操作","slug":"hdfs-的基本操作","link":"#hdfs-的基本操作","children":[{"level":3,"title":"Hadoop fs 和 hdfs dfs的区别","slug":"hadoop-fs-和-hdfs-dfs的区别","link":"#hadoop-fs-和-hdfs-dfs的区别","children":[]}]}],"readingTime":{"minutes":8.44,"words":2532},"git":{"createdTime":1729400552000,"updatedTime":1729400552000,"contributors":[{"name":"jerrysheh","email":"jerrysheh@gmail.com","commits":1}]},"autoDesc":true,"filePathRelative":"posts/bigdata/hadoop/Hadoop大数据生态（一）初识.md","categoryList":[{"id":"18958e","sort":10000,"name":"posts"},{"id":"e8c0d3","sort":10001,"name":"bigdata"},{"id":"b13d0a","sort":10017,"name":"hadoop"}]}');export{h as comp,u as data};
