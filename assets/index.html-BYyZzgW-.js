import{_ as i,c as e,f as a,o as t}from"./app-D22ydJtp.js";const n={};function l(r,s){return t(),e("div",null,s[0]||(s[0]=[a(`<p>Spark 支持多种文件格式的读写，包括</p><ul><li>本地文本文件：Json、SequenceFile 等文件格式</li><li>文件系统：HDFS、Amazon S3</li><li>数据库：MySQL、HBase、Hive</li></ul><hr><h1 id="本地文件读写" tabindex="-1"><a class="header-anchor" href="#本地文件读写"><span>本地文件读写</span></a></h1><h2 id="文本文件" tabindex="-1"><a class="header-anchor" href="#文本文件"><span>文本文件</span></a></h2><p>使用以下语句从文件系统中读写文件</p><div class="language-scala line-numbers-mode" data-ext="scala" data-title="scala"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">val</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> text</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;"> =</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> sc.textFile(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">file:///home/jerrysheh/word.txt</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">// .first() 是一个&quot;action&quot;</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">text.first()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">// 从RDD写回文件系统，saveAsTextFile是一个action</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">text.saveAsTextFile(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">file:///home/jerrysheh/wordWriteBack</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>spark的惰性机制使得在“转换”操作时，即使遇到错误也不会立即报错，直到”行动（action）“操作时才开始真正的计算，这时候如果有错误才会报错。</p></blockquote><p>wordWriteBack 是一个文件夹，写回后存放在该文件夹里，里面有part-00000 和 _SUCCESS 两个文件。part-00000 里面的内容就是写会的内容。</p><p>当我们想把输出的结果再次加载到RDD中，只要在<code>textFile()</code>中定位到 wordWriteBack 这个目录即可。</p><div class="language-scala line-numbers-mode" data-ext="scala" data-title="scala"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">val</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> text</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;"> =</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> sc.textFile(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">file:///home/jerrysheh/wordWriteBack</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="json文件" tabindex="-1"><a class="header-anchor" href="#json文件"><span>json文件</span></a></h2><div class="language-scala line-numbers-mode" data-ext="scala" data-title="scala"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">// jsonStr的类型是：org.apache.spark.rdd.RDD[String]</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">val</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> jsonStr</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;"> =</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> sc.textFile(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">file:///home/jerrysheh/people.json</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;">// 使用 foreach 遍历</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">jsonStr.foreach(println)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出：</p><div class="language- line-numbers-mode" data-ext="" data-title=""><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span>{&quot;name&quot;:&quot;Michael&quot;}</span></span>
<span class="line"><span>{&quot;name&quot;:&quot;Andy&quot;, &quot;age&quot;:30}</span></span>
<span class="line"><span>{&quot;name&quot;:&quot;Justin&quot;, &quot;age&quot;:19}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以用 scala 自带的 JSON 库 —— scala.util.parsing.json.JSON 进行解析。</p><hr><h1 id="从hdfs读写" tabindex="-1"><a class="header-anchor" href="#从hdfs读写"><span>从HDFS读写</span></a></h1><p>跟本地文件类似，只不过把 <code>file://</code> 换成 <code>hdfs://</code></p><div class="language-scala line-numbers-mode" data-ext="scala" data-title="scala"><button class="copy" title="复制代码" data-copied="已复制"></button><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">val</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> textFile</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;"> =</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> sc.textFile(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">hdfs://localhost:9000/user/jerrysheh/word.txt</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><hr>`,21)]))}const h=i(n,[["render",l],["__file","index.html.vue"]]),d=JSON.parse('{"path":"/article/kz5mtpu8/","title":"Spark中的数据读写","lang":"zh-CN","frontmatter":{"title":"Spark中的数据读写","comments":true,"categories":["大数据","Spark"],"tags":["大数据"],"abbrlink":"e884ae58","createTime":"2018/06/21 14:05:40","permalink":"/article/kz5mtpu8/","description":"Spark 支持多种文件格式的读写，包括 本地文本文件：Json、SequenceFile 等文件格式 文件系统：HDFS、Amazon S3 数据库：MySQL、HBase、Hive 本地文件读写 文本文件 使用以下语句从文件系统中读写文件 spark的惰性机制使得在“转换”操作时，即使遇到错误也不会立即报错，直到”行动（action）“操作时才开始...","head":[["meta",{"property":"og:url","content":"https://jerrysheh.com/article/kz5mtpu8/"}],["meta",{"property":"og:site_name","content":"Jerry"}],["meta",{"property":"og:title","content":"Spark中的数据读写"}],["meta",{"property":"og:description","content":"Spark 支持多种文件格式的读写，包括 本地文本文件：Json、SequenceFile 等文件格式 文件系统：HDFS、Amazon S3 数据库：MySQL、HBase、Hive 本地文件读写 文本文件 使用以下语句从文件系统中读写文件 spark的惰性机制使得在“转换”操作时，即使遇到错误也不会立即报错，直到”行动（action）“操作时才开始..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-10-20T05:02:32.000Z"}],["meta",{"property":"article:tag","content":"大数据"}],["meta",{"property":"article:modified_time","content":"2024-10-20T05:02:32.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Spark中的数据读写\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-10-20T05:02:32.000Z\\",\\"author\\":[]}"]]},"headers":[{"level":2,"title":"文本文件","slug":"文本文件","link":"#文本文件","children":[]},{"level":2,"title":"json文件","slug":"json文件","link":"#json文件","children":[]}],"readingTime":{"minutes":1.13,"words":340},"git":{"createdTime":1729400552000,"updatedTime":1729400552000,"contributors":[{"name":"jerrysheh","email":"jerrysheh@gmail.com","commits":1}]},"autoDesc":true,"filePathRelative":"posts/bigdata/spark/Spark中的数据读写.md","categoryList":[{"id":"18958e","sort":10000,"name":"posts"},{"id":"e8c0d3","sort":10001,"name":"bigdata"},{"id":"5133c6","sort":10019,"name":"spark"}]}');export{h as comp,d as data};
