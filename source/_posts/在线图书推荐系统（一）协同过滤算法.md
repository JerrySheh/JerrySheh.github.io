---
title: 在线图书推荐系统（一）协同过滤原理和数据集准备
comments: true
categories: 大数据
tags: 大数据
abbrlink: 6d329abe
date: 2018-05-13 15:24:24
---

最近要做一个简易的在线图书推荐系统，这个项目可能成为之后我的毕业设计。所以将学习的每一步记录下来。

参考教程：

- [Part I: Building the recommender](https://github.com/jadianes/spark-movie-lens/blob/master/notebooks/building-recommender.ipynb)
- [Part II: Building and running the web service](https://github.com/jadianes/spark-movie-lens)
- [厦门大学数据库实验室](http://dblab.xmu.edu.cn/blog/1781-2/)

参考书籍：

- [大数据技术原理与应用 林子雨（人民邮电出版社）](http://dblab.xmu.edu.cn/post/bigdata/)

参考链接：

- [Spark 官方文档- Collaborative Filtering](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)
- [Github项目 - An on-line movie recommender using Spark, Python Flask, and the MovieLens dataset](https://github.com/jadianes/spark-movie-lens)
- [在线图书推荐系统的实现（协同过滤）](https://www.jianshu.com/p/32d7a2d993a8)
- [Github项目 - spark-book-recommender-system](https://github.com/XuefengHuang/RecommendationSystem)

<!-- more -->

---

# 协同过滤（Collaborative Filtering）思想

什么是协同过滤呢，举个简单的例子，如果你不知道哪一部电影是自己喜欢的或者评分比较高的，那么通常的做法就是问问周围的朋友，看看最近有什么好的电影推荐。而在问的时候，肯定都习惯于问跟自己口味差不多的朋友。

协同过滤的本质是对用户喜好进行预测，其思想是根据邻居用户(与目标用户兴趣相似的用户)的偏好信息，计算出某用户对某商品的感兴趣度。

![example](https://camo.githubusercontent.com/a6e062883b83adb3b65b5a9e167a3a6f5e5f9a19/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f352f35322f436f6c6c61626f7261746976655f66696c746572696e672e676966)

协同过滤的一个基本假设（underlying assumption）是，用户A 和 用户B 如果对某些商品持有相同的观点，那么 用户A 跟 用户B 对 另一些商品 的观点会更接近。

如果我们用一个用户-产品矩阵来描述用户对产品的喜好程度，那么协同过滤算法的目标就是填充缺失的元素，如下图所示。（These techniques aim to fill in the missing entries of a user-item association matrix）

![fill](../../../../images/hadoop/cf.png)

---

# Spark 中的协同过滤算法

协同过滤算法主要分为基于用户的协同过滤算法和基于项目的协同过滤算法。

spark.ml 库当前支持基于模型的协同过滤，其中用户和商品通过一小组隐语义因子(latent factors)进行表达，并且这些因子也用于预测缺失的元素。spark.ml使用 `交替最小二乘法 (Alternating Least Squares. ALS)` 来学习这些隐性语义因子。


## 隐性反馈（implicit feedback）和显性反馈（explicit feedback）

显性反馈行为包括用户明确表示对物品喜好的行为，隐性反馈行为指的是那些不能明确反应用户喜好的行为。现实生活很多场景中，我们常常只能接触到隐性反馈，例如页面游览，点击，购买，喜欢，分享等等。

基于矩阵分解的协同过滤一般将用户商品矩阵中的元素作为用户对商品的显性偏好。

而 spark.ml 中所用到的处理这种数据的方法来源于文献： [Collaborative Filtering for Implicit Feedback Datasets](http://dx.doi.org/10.1109/ICDM.2008.22) 。 本质上，这个方法将数据作为二元偏好值和偏好强度的一个结合，而不是对评分矩阵直接进行建模。因此，评价就不是与用户对商品的显性评分，而是与所观察到的用户偏好强度关联起来。然后，这个模型将尝试找到隐语义因子来预估一个用户对一个商品的偏好。

---

# 前期准备

## 数据集下载

这里使用 [Book-Crossing](http://www2.informatik.uni-freiburg.de/~cziegler/BX/) 的数据集进行学习。

该数据集包含三个部分：

- 用户数据 BX-User.csv

0|1|2|
---|---|---
 "User-ID"|"Location"|"Age"

```
"1";"nyc, new york, usa";NULL
"2";"stockton, california, usa";"18"
"3";"moscow, yukon territory, russia";NULL
"4";"porto, v.n.gaia, portugal";"17"
```



- 图书数据 BX-Books.csv

0|1|2|3|4|5|6|7
 ---|---|---|---|---|---|---|---
 "ISBN"|"Book-Title"|"Book-Author"|"Year-Of-Publication"|"Publisher"|"Image-URL-S"|"Image-URL-M"|"Image-URL-L"

```
"0195153448";"Classical Mythology";"Mark P. O. Morford";"2002";"Oxford University Press";"http://images.amazon.com/images/P/0195153448.01.THUMBZZZ.jpg";"http://images.amazon.com/images/P/0195153448.01.MZZZZZZZ.jpg";"http://images.amazon.com/images/P/0195153448.01.LZZZZZZZ.jpg"
"0002005018";"Clara Callan";"Richard Bruce Wright";"2001";"HarperFlamingo Canada";"http://images.amazon.com/images/P/0002005018.01.THUMBZZZ.jpg";"http://images.amazon.com/images/P/0002005018.01.MZZZZZZZ.jpg";"http://images.amazon.com/images/P/0002005018.01.LZZZZZZZ.jpg"
```



- 用户对图书的评分数据 BX-Book-Ratings.csv

0|1|2|
---|---|---
"User-ID"|"ISBN"|"Book-Rating"

```
"276725";"034545104X";"0"
"276726";"0155061224";"5"
"276727";"0446520802";"0"
"276729";"052165615X";"3"
"276729";"0521795028";"6"
```

## 用 Python 提取关键信息

可以用 Python 的 `split()` 方法，对数据集信息进行分割以备装入 RDDs

需要对 图书数据集 和 评分数据集 进行处理：

- 对于评分数据集，创建一个 tuple 包含 (UserID, BookID, Rating)
- 对于图书数据集，创建一个 tuple 包含 (ISBN，Book-Title，Book-Author，Year-Of-Publication，Publisher，Image-URL-L)


评分数据

```python
# Load ratings data for later use
logger.info("Loading Ratings data...")
ratings_file_path = os.path.join(dataset_path, 'BX-Book-Ratings.csv')
ratings_raw_RDD = self.sc.textFile(ratings_file_path)
ratings_raw_data_header = ratings_raw_RDD.take(1)[0]
self.ratings_RDD = ratings_raw_RDD.filter(lambda line: line!=ratings_raw_data_header)\
    .map(lambda line: line.split(";"))\
    .map(lambda tokens: (int(tokens[0][1:-1]), abs(hash(tokens[1][1:-1])) % (10 ** 8), int(tokens[2][1:-1]))).cache()
```

图书数据

```python
# Load books data for later use
logger.info("Loading Books data...")
books_file_path = os.path.join(dataset_path, 'BX-Books.csv')
books_raw_RDD = self.sc.textFile(books_file_path)
books_raw_data_header = books_raw_RDD.take(1)[0]
self.books_RDD = books_raw_RDD.filter(lambda line: line!=books_raw_data_header)\
    .map(lambda line: line.split(";"))\
    .map(lambda tokens: (abs(hash(tokens[0][1:-1])) % (10 ** 8), tokens[1][1:-1], tokens[2][1:-1], tokens[3][1:-1], tokens[4][1:-1], tokens[5][1:-1])).cache()
self.books_titles_RDD = self.books_RDD.map(lambda x: (int(x[0]), x[1], x[2], x[3], x[4], x[5])).cache()
```

未完待续
